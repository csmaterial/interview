### 机器学习算法
##### 1. 线性模型
1.1 LR
1）LR 的推导
	- 目标函数：似然损失
	- 优化方法：
		- 梯度下降
		- 牛顿法
	- LR 为什么用 sigmoid 函数？这个函数有什么优点和缺点？为什么不用其他函数？
	
2）模型对比
	- LR 和线性回归区别？线性回归可以用来做正负分类么？
	- LR 和 SVM 区别？
	- LR 和最大熵模型的关系？
	
3）模型实现
	- 并行实现

##### 2. SVM
1）SVM 的推导
	- 目标函数：最大间隔
		- 原始问题和对偶问题？对偶问题的好处？
		- KKT 条件
		- 合页损失函数是针对原始问题还是对偶问题？
		
	- 优化方法：
		- SMO
		- SMO 算法的时间复杂度和空间复杂度？
		
	- SVM 怎么防止过拟合
	
2）其他问题
	- SVM 为什么不适合处理大数据？SMO 也不行？为什么适合小样本多特征？LR 适用什么情况？

##### 3. 树模型
1）基础决策树模型：ID3，C4.5，CART
	- 分裂节点的选择
		- 信息增益
		- 信息增益比
		- 基尼指数
		
	- 决策树剪枝
		- CART 树剪枝（递归的方法）
		
	- 决策树损失函数
		- 正则化的最大似然怎么解释？
		
	- 决策树怎么处理连续值？
2）集成学习
	- bagging：随机森林
		- 随机森林怎么防止过拟合？
		
	- boosting
		- Adaboost
		
		- GBDT
			- GBDT
				- GBDT 原理？加法模型
				- GBDT 分裂节点的选择？
				- GBDT 怎么并发？
				- GBDT 为什么用梯度拟合残差？
				
			- XGBoost
				- XGBoost 目标函数？
				- XGBoost 怎么做并行？
				- XGBoost 与 传统 GBDT 区别？
				- XGBoost 对特征缺失敏感么？对缺失值做了什么操作？哪些模型对缺失值敏感？哪些不敏感？
				
			- LightGBM


##### 4. 聚类方法
1）k-means
	- 原理
	- 与 EM 算法的关系
	- k 怎么确定
	- 缺点及改进

参考：
- [k-means 聚类算法](http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006910.html)

##### 5. 最大熵模型

##### 6. 正则
- 为什么正则化可以防止过拟合？
- L1 正则为什么可以把系数压缩成 0？如何解决 L1 求导困难？
- L0.5 正则可以获得稀疏解么？L1.5 正则呢？


##### 7. 优化方法
1）梯度下降
	- 梯度下降的种类
		- 批量梯度下降
		- 随机梯度下降
		- mini-batch 梯度下降
	- 梯度下降算法的优缺点
	- 为什么负梯度方向是函数值下降最快的方向？
	- 随机梯度下降为什么能够收敛到最小值点？
	
2）牛顿法
	- 牛顿法
	- 拟牛顿法
	
3）坐标下降法



参考资料：

1）[为什么梯度反方向是函数值下降最快的方向？](https://zhuanlan.zhihu.com/p/24913912)

##### 8. 机器学习评价指标
1）假设加了很多负例，AUC 和 PRC 哪个对此不敏感？（实际上 AUC 不敏感，但也有人说 PRC 比 AUC 在极端不平衡时
曲线差很多，所以用 PRC 能反映真实的效果）

参考资料：

1）[精确率、召回率、F1 值、ROC、AUC 各自的优缺点是什么？](https://www.zhihu.com/question/30643044)

##### 9. 机器学习理论
1）VC 维

2）偏差-方差分解

3）什么是过拟合？为什么会过拟合？怎么判断过拟合？怎么解决过拟合？

4）判别模型和生成模型？

### 机器学习应用
1）数据清洗及预处理
- 缺失值填充方法？
- 为什么要做归一化？哪些模型要做归一化？哪些不用？归一化的方式？
- 数据不平衡问题怎么处理？

2）特征工程

3）特征选择

4）过拟合的解决方法

5）树形结构，SVM，LR 都适用什么场景？Boosting，随机森林适用于什么场景？





##### 其他问题
- 有一堆已经分好的词，如何发现新词？

用这个词和左右词的关系。互信息 新词的左右比较丰富，有的老词的左右也比较丰富。还要区分出新词和老词。

参考：[反作弊基于左右信息熵和互信息的新词挖掘](https://zhuanlan.zhihu.com/p/25499358?hmsr=toutiao.io&utm_medium=toutiao.io&utm_source=toutiao.io)


